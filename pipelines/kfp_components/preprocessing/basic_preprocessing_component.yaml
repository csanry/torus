name: Basic preprocessing
inputs:
- {name: input_file, type: String}
- {name: output_bucket, type: String}
- {name: output_file, type: String}
outputs:
- {name: Output, type: String}
implementation:
  container:
    image: gcr.io/pacific-torus-347809/mle-fp/base:latest
    command:
    - sh
    - -c
    - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'fsspec' 'gcsfs' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet
      --no-warn-script-location 'fsspec' 'gcsfs' --user) && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - "def basic_preprocessing(\n    input_file,\n    output_bucket,\n    output_file,\n\
      ): \n\n    from functools import reduce\n\n    import pandas as pd\n\n    df\
      \ = pd.read_csv(input_file)\n\n    df.columns = [col.lower().rstrip('_') for\
      \ col in df.columns] \n    df.dropna(inplace=True)\n\n    df[\"target\"] = df[\"\
      default\"].apply(lambda row: 1 if row else 0)\n\n    df.loc[df[\"education\"\
      ] == \"0\", \"education\"] = \"Unknown\"\n    education = pd.get_dummies(df[\"\
      education\"], prefix='ed')\n\n    df.loc[df[\"marriage\"] == \"0\", \"marriage\"\
      ] = \"Other\"\n    marriage = pd.get_dummies(df[\"marriage\"], prefix='mstatus')\n\
      \n    sex = pd.get_dummies(df[\"sex\"], prefix='gender')\n\n    frames = [df,\
      \ sex, education, marriage]\n    final = reduce(lambda l, r: pd.concat([l, r],\
      \ axis=1), frames)\n    final.drop(columns=['id', 'default', 'sex', 'education',\
      \ 'marriage'], inplace=True)\n\n    output_path = f\"gs://mle-dwh-torus/{output_bucket}/{output_file}\"\
      \ \n    final.to_csv(output_path, index=False)\n\n    return output_path\n\n\
      def _serialize_str(str_value: str) -> str:\n    if not isinstance(str_value,\
      \ str):\n        raise TypeError('Value \"{}\" has type \"{}\" instead of str.'.format(\n\
      \            str(str_value), str(type(str_value))))\n    return str_value\n\n\
      import argparse\n_parser = argparse.ArgumentParser(prog='Basic preprocessing',\
      \ description='')\n_parser.add_argument(\"--input-file\", dest=\"input_file\"\
      , type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
      --output-bucket\", dest=\"output_bucket\", type=str, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--output-file\", dest=\"output_file\", type=str, required=True,\
      \ default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\", dest=\"\
      _output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n\
      _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = basic_preprocessing(**_parsed_args)\n\
      \n_outputs = [_outputs]\n\n_output_serializers = [\n    _serialize_str,\n\n\
      ]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n    try:\n\
      \        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n  \
      \      pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
    args:
    - --input-file
    - {inputValue: input_file}
    - --output-bucket
    - {inputValue: output_bucket}
    - --output-file
    - {inputValue: output_file}
    - '----output-paths'
    - {outputPath: Output}
