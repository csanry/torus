name: Predict
inputs:
- {name: model_input_file, type: String}
- {name: serving_container_image_uri, type: String}
- {name: project_id, type: String}
- {name: region, type: String}
implementation:
  container:
    image: gcr.io/pacific-torus-347809/mle-fp/base:latest
    command:
    - sh
    - -c
    - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'pandas' 'gcsfs' 'fsspec' 'sklearn' 'xgboost' || PIP_DISABLE_PIP_VERSION_CHECK=1
      python3 -m pip install --quiet --no-warn-script-location 'pandas' 'gcsfs' 'fsspec'
      'sklearn' 'xgboost' --user) && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - |
      def predict(
              model_input_file,
              serving_container_image_uri,
              project_id,
              region
      ):

          from google.cloud import aiplatform
          aiplatform.init(project=project_id, location=region)

          DISPLAY_NAME  = "Credit-Card-Default-Check-RF3"
          MODEL_NAME = "CCD-RF3"
          ENDPOINT_NAME = "Credit-Card-Default-Check-Endpoint3"

          def create_endpoint():
              endpoints = aiplatform.Endpoint.list(
                  filter='display_name="{}"'.format(ENDPOINT_NAME),
                  order_by='create_time desc',
                  project=project_id,
                  location=region,
              )
              if len(endpoints) > 0:
                  endpoint = endpoints[0]
              else:
                  endpoint = aiplatform.Endpoint.create(
                      display_name=ENDPOINT_NAME, project=project_id, location=region
                  )
              return endpoint

          endpoint = create_endpoint()

          model_upload = aiplatform.Model.upload(
              display_name = DISPLAY_NAME,
              artifact_uri = model_input_file,
              serving_container_image_uri =  serving_container_image_uri,
              serving_container_health_route=f"/v1/models/{MODEL_NAME}",
              serving_container_predict_route=f"/v1/models/{MODEL_NAME}:predict",
              serving_container_environment_variables={
              "MODEL_NAME": MODEL_NAME,
              })

          model_deploy = model_upload.deploy(
              machine_type="n1-standard-4",
              endpoint=endpoint,
              traffic_split={"0": 100},
              deployed_model_display_name=DISPLAY_NAME,
          )

          #vertex_model.uri = model_deploy.resource_name
          # from collections import namedtuple
          #
          # results = namedtuple("outputs", ["train_data", "test_data"])
          #
          # return results(train, test)

      import argparse
      _parser = argparse.ArgumentParser(prog='Predict', description='')
      _parser.add_argument("--model-input-file", dest="model_input_file", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--serving-container-image-uri", dest="serving_container_image_uri", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--project-id", dest="project_id", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--region", dest="region", type=str, required=True, default=argparse.SUPPRESS)
<<<<<<< HEAD
      _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=2)
      _parsed_args = vars(_parser.parse_args())
      _output_files = _parsed_args.pop("_output_paths", [])

      _outputs = predict(**_parsed_args)

      _output_serializers = [
          str,
          str,

      ]

      import os
      for idx, output_file in enumerate(_output_files):
          try:
              os.makedirs(os.path.dirname(output_file))
          except OSError:
              pass
          with open(output_file, 'w') as f:
              f.write(_output_serializers[idx](_outputs[idx]))
=======
      _parsed_args = vars(_parser.parse_args())

      _outputs = predict(**_parsed_args)
>>>>>>> d0878459ec0438b6d3662422f40099d10e2cac11
    args:
    - --model-input-file
    - {inputValue: model_input_file}
    - --serving-container-image-uri
    - {inputValue: serving_container_image_uri}
    - --project-id
    - {inputValue: project_id}
    - --region
    - {inputValue: region}
<<<<<<< HEAD
    - '----output-paths'
    - {outputPath: vertex_endpoint}
    - {outputPath: vertex_model}
=======
>>>>>>> d0878459ec0438b6d3662422f40099d10e2cac11
