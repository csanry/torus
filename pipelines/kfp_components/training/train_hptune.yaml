name: Train hptune
inputs:
- {name: train_file, type: String}
outputs:
- {name: final_model, type: String}
implementation:
  container:
    image: gcr.io/pacific-torus-347809/mle-fp/base:latest
    command:
    - sh
    - -c
    - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'xgboost' 'gcsfs' 'sklearn' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip
      install --quiet --no-warn-script-location 'xgboost' 'gcsfs' 'sklearn' --user)
      && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - |
      def train_hptune(
              train_file,
              #model_bucket: str,
      ):

          from xgboost import XGBClassifier
          from google.cloud import storage
          from sklearn.model_selection import RandomizedSearchCV
          import pandas as pd
          import os
          import pickle

          train_df = pd.read_csv(train_file)

          print(train_df.head())
          PARAMS = {
              'n_estimators': [200, 300, 400],
              'learning_rate': [0.01, 0.1, 1]
          }

          XGB = XGBClassifier()
          PARAM_COMB = 3

          random_search = RandomizedSearchCV(XGB,
                                             param_distributions=PARAMS,
                                             n_iter=PARAM_COMB,
                                             scoring='accuracy',
                                             verbose=3,
                                             random_state=2022
                                             )

          random_search.fit(train_df.drop(columns=["target"]), train_df.target)
          best_params = random_search.best_params_
          best_score = random_search.best_score_

          xg_model = XGBClassifier(**best_params)
          xg_model.fit(train_df.drop(columns=["target"]), train_df.target)
          score = xg_model.score(train_df.drop(columns=["target"]), train_df.target)

          artifact_filename = 'model.pkl'
          # Save model artifact to local filesystem (doesn't persist)
          local_path = artifact_filename
          with open(local_path, 'wb') as model_file:
              pickle.dump(xg_model, model_file)
          # os.environ['AIP_MODEL_DIR'] = "gs://mle-dwh-torus/models/deployed/"
          # Upload model artifact to Cloud Storage
          model_directory = "gs://mle-dwh-torus/models/deployed/"
          storage_path = os.path.join(model_directory, artifact_filename)
          blob = storage.blob.Blob.from_string(storage_path, client=storage.Client())
          blob.upload_from_filename(local_path)

          # model_output_path = "gs://mle-dwh-torus/models/deployed/model.pkl"
          # # final_model = xg_model.save_model(model_output_path)
          # #
          # # file_name = final_model.path + f".pkl"
          # with open(model_output_path, 'wb') as file:
          #     pickle.dump(xg_model, file)
          #
          final_model.metadata["framework"] = "XGBoost"
          final_model.metadata["train_score"] = float(score)
          #
          from collections import namedtuple

          results = namedtuple("outputs", ["final_model", ])

          return results(storage_path,)

      def _serialize_str(str_value: str) -> str:
          if not isinstance(str_value, str):
              raise TypeError('Value "{}" has type "{}" instead of str.'.format(
                  str(str_value), str(type(str_value))))
          return str_value

      import argparse
      _parser = argparse.ArgumentParser(prog='Train hptune', description='')
      _parser.add_argument("--train-file", dest="train_file", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
      _parsed_args = vars(_parser.parse_args())
      _output_files = _parsed_args.pop("_output_paths", [])

      _outputs = train_hptune(**_parsed_args)

      _output_serializers = [
          _serialize_str,

      ]

      import os
      for idx, output_file in enumerate(_output_files):
          try:
              os.makedirs(os.path.dirname(output_file))
          except OSError:
              pass
          with open(output_file, 'w') as f:
              f.write(_output_serializers[idx](_outputs[idx]))
    args:
    - --train-file
    - {inputValue: train_file}
    - '----output-paths'
    - {outputPath: final_model}
