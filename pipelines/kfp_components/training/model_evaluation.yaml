name: Model evaluation
inputs:
- {name: trained_model, type: String}
- {name: train_auc, type: Float}
- {name: test_set, type: String}
- {name: threshold, type: Float}
- name: deploy
  type: String
  default: "False"
  optional: true
outputs:
- {name: model_test, type: ClassificationMetrics}
- {name: deploy, type: String}
- {name: evaluated_model, type: String}
implementation:
  container:
    image: gcr.io/pacific-torus-347809/mle-fp/base:latest
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'pandas' 'gcsfs' 'fsspec' 'sklearn' 'xgboost' 'kfp==1.8.12' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing\
      \ import *\n\ndef model_evaluation(\n        trained_model: str,\n        train_auc:\
      \ float,\n        test_set: str,\n        model_test: Output[ClassificationMetrics],\n\
      \        threshold: float,\n        deploy: str = 'False',\n) -> NamedTuple(\"\
      outputs\", [('deploy', str), ('evaluated_model', str)]):\n    from google.cloud\
      \ import storage\n    import os\n    import pandas as pd\n    import pickle\n\
      \    import json\n    from sklearn.ensemble import RandomForestClassifier\n\
      \    from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve\n\
      \n    # Load Datasets and Models\n    data = pd.read_csv(test_set)\n    model\
      \ = RandomForestClassifier()\n\n    model_bucket = trained_model.split(\"/\"\
      )[2]\n    object_name = \"/\".join(trained_model.split(\"/\")[3:])\n\n    client\
      \ = storage.Client()\n    bu = client.bucket(model_bucket)\n    b = bu.blob(object_name)\n\
      \    b.download_to_filename('model.pkl')\n    model = pickle.load(open('model.pkl',\
      \ 'rb'))\n\n    X = data.drop(['target'], axis=1)\n    Y = data['target']\n\n\
      \    y_prob = model.predict_proba(X)[:, 1]\n    y_pred = model.predict(X)\n\
      \    test_auc = roc_auc_score(Y, y_prob)\n    fpr, tpr, thresholds = roc_curve(Y,\
      \ y_prob, pos_label=1)\n\n    # Add model performance metadata\n    model_test.metadata['test_auc']\
      \ = test_auc\n    model_test.log_roc_curve(fpr.tolist(), tpr.tolist(), thresholds.tolist())\n\
      \    model_test.log_confusion_matrix(['No Default', 'Default'], confusion_matrix(Y,\
      \ y_pred).tolist())\n\n    # Also export in a json in the model path\n    model_info\
      \ = {\n        'framework': 'RF',\n        'train_auc': train_auc,\n       \
      \ 'test_auc': test_auc,\n        'confusion_matrix': {'classes': [0, 1], 'matrix':\
      \ confusion_matrix(Y, y_pred).tolist()}\n    }\n\n    # Make Checks Before Deployment\
      \ \n    # Check if a deployed model exists with associated information and make\
      \ performance comparisons\n\n    model_info_loc = \"gs://mle-dwh-torus/models/deployed/model_info.json\"\
      \n    info_bucket = model_info_loc.split(\"/\")[2]\n    file_name = \"/\".join(model_info_loc.split(\"\
      /\")[3:])\n    bucket = client.bucket(info_bucket)\n    info_exists = storage.Blob(bucket=bucket,\
      \ name=file_name).exists(client)\n    model_output_path = 'gs://mle-dwh-torus/models/deployed/'\n\
      \    model_info_filename = 'model_info.json'\n    model_filename = 'model.pkl'\n\
      \n    info_storage_path = os.path.join(model_output_path, model_info_filename)\n\
      \    model_storage_path = os.path.join(model_output_path, model_filename)\n\n\
      \    from collections import namedtuple\n    results = namedtuple(\"outputs\"\
      , ['deploy', 'evaluated_model'])\n\n    def set_params_upload():\n        with\
      \ open('model.pkl', 'wb') as model_file:\n            pickle.dump(model, model_file)\n\
      \n        info_blob = storage.blob.Blob.from_string(info_storage_path, client=storage.Client())\n\
      \        model_blob = storage.blob.Blob.from_string(model_storage_path, client=storage.Client())\n\
      \        info_blob.upload_from_string(data=json.dumps(model_info), content_type='application/json')\n\
      \        model_blob.upload_from_filename('model.pkl')\n\n    if not info_exists\
      \ and test_auc > threshold:\n        deploy = 'True'\n        set_params_upload()\n\
      \        model_loc = \"gs://mle-dwh-torus/models/deployed/model.pkl\"\n    \
      \    return results(deploy, model_loc)\n\n    elif info_exists:\n        blob\
      \ = bucket.get_blob(file_name)\n        info = json.loads(blob.download_as_string())\n\
      \n        if test_auc >= info['test_auc']:\n            deploy = 'True'\n  \
      \          set_params_upload()\n            model_loc = \"gs://mle-dwh-torus/models/deployed/model.pkl\"\
      \n            return results(deploy, model_loc)\n\n        else:\n         \
      \   return results(deploy, \"Challenger model failed\")\n\n"
    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - model_evaluation
