{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLARENCE\n",
    "#### Notebook primarily for testing components "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18 Jun \n",
    "Pipeline not running as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pipelines.kfp.dependencies'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rs/_9wv_fmn5y1d1cxb6xd4q711dh2rk4/T/ipykernel_51197/1543457443.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompiler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpipelines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpipelines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkfp_components\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mingest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbq_extract_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbq_query_to_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git/mle/pipelines/kfp/helpers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcreate_bucket\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_bucket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdelete_bucket\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdelete_bucket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msetup_credentials\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msetup_credentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git/mle/pipelines/kfp/helpers/create_bucket.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpipelines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdependencies\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBUCKET_LOCATION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOGGING_CONF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPROJECT_ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpipelines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_credentials\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msetup_credentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pipelines.kfp.dependencies'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "from google_cloud_pipeline_components.experimental.custom_job.utils import (\n",
    "    create_custom_training_job_op_from_component,\n",
    ")\n",
    "\n",
    "from kfp.v2 import compiler, dsl\n",
    "from pipelines.kfp.helpers import generate_query\n",
    "\n",
    "from pipelines.kfp_components.ingest import bq_extract_data, bq_query_to_table\n",
    "from pipelines.kfp_components.training import train_xgboost_model\n",
    "# from pipelines.kfp_components.dependencies import PROJECT_ID, ROOT_DIR, sql_query\n",
    "\n",
    "print(ROOT_DIR)\n",
    "\n",
    "@dsl.pipeline(name=\"xgboost-train-pipeline\")\n",
    "def old_xgboost_pipeline(\n",
    "    # project_id: str,\n",
    "    # project_location: str,\n",
    "    # pipeline_files_gcs_path: str,\n",
    "    # ingestion_project_id: str,\n",
    "    # tfdv_schema_filename: str,\n",
    "    # tfdv_train_stats_path: str,\n",
    "    # model_name: str,\n",
    "    # model_label: str,\n",
    "    # dataset_id: str,\n",
    "    # dataset_location: str,\n",
    "    # ingestion_dataset_id: str,\n",
    "    # timestamp: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Query a view from BQ\n",
    "    Extract the view to GCS\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    sql_query = generate_query(\n",
    "        input_file=ROOT_DIR\n",
    "        / \"pipelines\"\n",
    "        / \"kfp\"\n",
    "        / \"ingest\"\n",
    "        / \"queries\"\n",
    "        / \"query_bq.sql\"\n",
    "    )\n",
    "\n",
    "    ingest = bq_query_to_table(\n",
    "        query=sql_query,\n",
    "        bq_client_project_id=None,\n",
    "        destination_project_id=PROJECT_ID,\n",
    "        dataset_id=\"dwh_pacific_torus\",\n",
    "        table_id=\"credit_card_default\",\n",
    "        dataset_location=\"US\",\n",
    "        query_job_config=None,\n",
    "    )\n",
    "    # .set_display_name(\"Ingest data\")\n",
    "\n",
    "    # ingest_to_gcs = (\n",
    "    #     bq_extract_data(\n",
    "    #         source_project_id=\"pacific-torus-347809\",\n",
    "    #         source_dataset_id=\"dwh_pacific_torus\",\n",
    "    #         source_table_id=\"credit_card_default\",\n",
    "    #         destination_project_id=\"pacific-torus-347809\",\n",
    "    #         destination_bucket=\"mle-dwh-torus\",\n",
    "    #         destination_file=\"raw/credit_cards.csv\",\n",
    "    #         dataset_location=\"US\",\n",
    "    #     )\n",
    "    #     # .after(ingest)\n",
    "    #     # .set_display_name(\"Export to GCS\")\n",
    "    # )\n",
    "\n",
    "\n",
    "def compile():\n",
    "\n",
    "    compiler.Compiler().compile(\n",
    "        pipeline_func=xgboost_pipeline,\n",
    "        pipeline_name=\"xgboost-train-pipeline\",\n",
    "        package_path=\"training.yaml\",\n",
    "        type_check=True,\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    custom_train_job = create_custom_training_job_op_from_component(\n",
    "        component_spec=train_xgboost_model,\n",
    "        replica_count=1,\n",
    "        machine_type=\"n1-standard-4\",\n",
    "    )\n",
    "\n",
    "    compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22 Jun Test ingest component step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import kfp\n",
    "from kfp.v2 import compiler, dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load kube config.\n"
     ]
    },
    {
     "ename": "MaxRetryError",
     "evalue": "HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /apis/v1beta1/healthz (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fb8ac2c78e0>: Failed to establish a new connection: [Errno 61] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             conn = connection.create_connection(\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                 \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_user_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1324\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSocketError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             raise NewConnectionError(\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7fb8ac2c78e0>: Failed to establish a new connection: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rs/_9wv_fmn5y1d1cxb6xd4q711dh2rk4/T/ipykernel_70823/143755967.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/kfp/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, host, client_id, namespace, other_client_id, other_client_secret, existing_token, cookies, proxy, ssl_ca_cert, kube_context, credentials, ui_host)\u001b[0m\n\u001b[1;32m    194\u001b[0m         self._healthz_api = kfp_server_api.api.healthz_service_api.HealthzServiceApi(\n\u001b[1;32m    195\u001b[0m             api_client)\n\u001b[0;32m--> 196\u001b[0;31m         if not self._context_setting['namespace'] and self.get_kfp_healthz(\n\u001b[0m\u001b[1;32m    197\u001b[0m         ).multi_user is True:\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/kfp/_client.py\u001b[0m in \u001b[0;36mget_kfp_healthz\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    408\u001b[0m                         max_attempts))\n\u001b[1;32m    409\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_healthz_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_healthz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;31m# ApiException, including network errors, is the only type that may\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/kfp_server_api/api/healthz_service_api.py\u001b[0m in \u001b[0;36mget_healthz\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \"\"\"\n\u001b[1;32m     62\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_return_http_data_only'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_healthz_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: E501\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_healthz_with_http_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E501\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/kfp_server_api/api/healthz_service_api.py\u001b[0m in \u001b[0;36mget_healthz_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mauth_settings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Bearer'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# noqa: E501\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         return self.api_client.call_api(\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;34m'/apis/v1beta1/healthz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mpath_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/kfp_server_api/api_client.py\u001b[0m in \u001b[0;36mcall_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \"\"\"\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0masync_req\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             return self.__call_api(resource_path, method,\n\u001b[0m\u001b[1;32m    365\u001b[0m                                    \u001b[0mpath_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                                    \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/kfp_server_api/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;31m# perform request and return response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             response_data = self.request(\n\u001b[0m\u001b[1;32m    182\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mpost_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpost_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/kfp_server_api/api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;34m\"\"\"Makes the HTTP request using RESTClient.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             return self.rest_client.GET(url,\n\u001b[0m\u001b[1;32m    390\u001b[0m                                         \u001b[0mquery_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                                         \u001b[0m_preload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/kfp_server_api/rest.py\u001b[0m in \u001b[0;36mGET\u001b[0;34m(self, url, headers, query_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    228\u001b[0m     def GET(self, url, headers=None, query_params=None, _preload_content=True,\n\u001b[1;32m    229\u001b[0m             _request_timeout=None):\n\u001b[0;32m--> 230\u001b[0;31m         return self.request(\"GET\", url,\n\u001b[0m\u001b[1;32m    231\u001b[0m                             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                             \u001b[0m_preload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/kfp_server_api/rest.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;31m# For `GET`, `HEAD`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                 r = self.pool_manager.request(method, url,\n\u001b[0m\u001b[1;32m    209\u001b[0m                                               \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                                               \u001b[0mpreload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/urllib3/request.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encode_url_methods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             return self.request_encode_url(\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/urllib3/request.py\u001b[0m in \u001b[0;36mrequest_encode_url\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0murl\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"?\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murlencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     def request_encode_body(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/urllib3/poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;34m\"Retrying (%r) after connection broken by '%r': %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             )\n\u001b[0;32m--> 813\u001b[0;31m             return self.urlopen(\n\u001b[0m\u001b[1;32m    814\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;34m\"Retrying (%r) after connection broken by '%r': %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             )\n\u001b[0;32m--> 813\u001b[0;31m             return self.urlopen(\n\u001b[0m\u001b[1;32m    814\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;34m\"Retrying (%r) after connection broken by '%r': %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             )\n\u001b[0;32m--> 813\u001b[0;31m             return self.urlopen(\n\u001b[0m\u001b[1;32m    814\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    783\u001b[0m                 \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProtocolError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Connection aborted.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    786\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Incremented Retry for (url='%s'): %r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=80): Max retries exceeded with url: /apis/v1beta1/healthz (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fb8ac2c78e0>: Failed to establish a new connection: [Errno 61] Connection refused'))"
     ]
    }
   ],
   "source": [
    "client = kfp.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_op = kfp.components.load_component_from_file(\"../ingest_component.yaml\")\n",
    "tfdv_op = kfp.components.load_component_from_file(\"../tfdv_component.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ingest_op.component_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "@dsl.pipeline(\n",
    "   name='testing pipeline',\n",
    "   description='NIL'\n",
    ")\n",
    "def xgboost_test_pipeline(\n",
    "):\n",
    "    ingest = ingest_op(\n",
    "        source_project_id=\"pacific-torus-347809\",\n",
    "        source_dataset_id=\"dwh_pacific_torus\",\n",
    "        source_table_id=\"credit_card_defaults\",\n",
    "        destination_project_id=\"pacific-torus-347809\",\n",
    "        destination_bucket=\"mle-dwh-torus\",\n",
    "        destination_file=\"raw/credit_cards.csv\",\n",
    "        dataset_location=\"US\",\n",
    "        extract_job_config=\"None\",\n",
    "    ) # .apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "\n",
    "    stats = tfdv_op(  # TFDV stats for the test data\n",
    "        input_data=\"gs://mle-dwh-torus/raw/credit_cards.csv\",\n",
    "        output_path=\"gs://mle-dwh-torus/tfdv_expers/eval/evaltest.pb\",\n",
    "        job_name='test-1',\n",
    "        use_dataflow=\"False\",\n",
    "        project_id=\"pacific-torus-347809\", \n",
    "        region=\"US\",\n",
    "        gcs_temp_location='gs://mle-dwh-torus/tfdv_expers/tmp',\n",
    "        gcs_staging_location='gs://mle-dwh-torus/tfdv_expers',\n",
    "        whl_location=\"None\", \n",
    "        requirements_file=\"requirements.txt\"\n",
    "    ).after(ingest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=xgboost_test_pipeline,\n",
    "    pipeline_name=\"xgboost-train-pipeline\",\n",
    "    package_path=\"test.json\",\n",
    "    type_check=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23 Jun Simple pipeline trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from kfp.v2.dsl import Dataset, Output, component, OutputPath, Artifact, Input\n",
    "import google.cloud.aiplatform as aip\n",
    "from kfp.v2 import compiler, dsl\n",
    "\n",
    "aip.init(project=\"pacific-torus-347809\", staging_bucket=\"gs://mle-dwh-torus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bq_extract_data(\n",
    "    source_project_id: str,\n",
    "    source_table_url: str,\n",
    "    destination_project_id: str,\n",
    "    destination_bucket: str, \n",
    "    destination_file: str,\n",
    "    dataset_location: str,\n",
    "    extract_job_config: dict = None,\n",
    ") -> NamedTuple('outputs', [('dataset_gcs_uri', str), \n",
    "    ('dataset_gcs_directory', str)]\n",
    "):\n",
    "\n",
    "    import logging\n",
    "    import os \n",
    "    from google.cloud.exceptions import GoogleCloudError\n",
    "    from google.cloud import bigquery, storage\n",
    "\n",
    "\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"pacific-torus.json\"\n",
    "\n",
    "    # logging.config.fileConfig(LOGGING_CONF)\n",
    "    logger = logging.getLogger(\"root\")\n",
    "\n",
    "    storage_client = storage.Client(project=destination_project_id)\n",
    "\n",
    "    if not storage.Bucket(storage_client, destination_bucket).exists():\n",
    "        bucket = storage_client.bucket(destination_bucket)\n",
    "        bucket.storage_class = \"STANDARD\" \n",
    "        storage_client.create_bucket(\n",
    "            bucket_or_name=bucket, location=\"ASIA-SOUTHEAST1\", project=destination_project_id\n",
    "        )\n",
    "        logger.info(f\"Bucket created {destination_bucket}\")\n",
    "\n",
    "    full_table_url = f\"{source_project_id}.{source_table_url}\"\n",
    "    table = bigquery.table.Table(table_ref=full_table_url)\n",
    "\n",
    "    if extract_job_config is None:\n",
    "        extract_job_config = {}\n",
    "    if destination_file.endswith(\".json\"):\n",
    "        extract_job_config = {\"destination_format\": \"NEWLINE_DELIMITED_JSON\"}\n",
    "    job_config = bigquery.ExtractJobConfig(**extract_job_config)\n",
    "\n",
    "\n",
    "    dataset_gcs_uri = f\"gs://{destination_bucket}/{destination_file}\"\n",
    " \n",
    "    bq_client = bigquery.Client(project=destination_project_id)\n",
    "\n",
    "    logger.info(f\"Extract {source_table_url} to {dataset_gcs_uri}\")\n",
    "    extract_job = bq_client.extract_table(\n",
    "        source=table,\n",
    "        destination_uris=dataset_gcs_uri,\n",
    "        job_config=job_config,\n",
    "        location=dataset_location,\n",
    "    )\n",
    "\n",
    "    dataset_gcs_directory = os.path.dirname(dataset_gcs_uri)\n",
    "\n",
    "    try:\n",
    "        extract_job.result()\n",
    "        logger.info(f\"Table extracted: {dataset_gcs_uri}\")\n",
    "    except GoogleCloudError as e:\n",
    "        logger.error(e)\n",
    "        logger.error(extract_job.error_result)\n",
    "        logger.error(extract_job.errors)\n",
    "        raise e\n",
    "\n",
    "    return (dataset_gcs_uri, dataset_gcs_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_preprocessing(\n",
    "    input_file: str,\n",
    "    output_bucket: str,\n",
    "    output_file: str\n",
    ") -> Artifact: \n",
    "\n",
    "    import pandas as pd\n",
    "    from functools import reduce\n",
    "\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    df.columns = [col.lower().strip() for col in df.columns] \n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    df.rename({'default_payment_next_month': \"default\"}, inplace=True)\n",
    "    df.loc[df['education'] == '0', 'education'] = 'Unknown'\n",
    "    df.loc[df['marriage'] == '0', 'marriage'] = 'Other'\n",
    "    sex = pd.get_dummies(df.sex, prefix='gender')\n",
    "    education = pd.get_dummies(df.education, prefix='ed')\n",
    "    marriage = pd.get_dummies(df.marriage, prefix='mstatus')\n",
    "    frames = [df, sex, education, marriage]\n",
    "    final = reduce(lambda l, r: pd.concat([l, r], axis=1), frames)\n",
    "    final.drop(['default_payment_next_month', 'sex', 'education', 'marriage'], axis=1, inplace=True)\n",
    "\n",
    "    output_path = f\"gs://mle-dwh-torus/{output_bucket}/{output_file}\" \n",
    "    final.to_csv(output_path, index=False)\n",
    "\n",
    "    return final\n",
    "\n",
    "\n",
    "def train_test_split(\n",
    "    input_file: InputPath(\"CSV\"),\n",
    "    output_bucket: str,\n",
    ") -> NamedTuple(\"outputs\", [\n",
    "    (\"train_data\", Artifact),\n",
    "    (\"test_data\", Artifact)\n",
    "]):\n",
    "\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    df = pd.read_csv(input_file)\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=2022)\n",
    "\n",
    "    output_train_path = f\"gs://mle-dwh-torus/{output_bucket}/train.csv\"\n",
    "    output_test_path = f\"gs://mle-dwh-torus/{output_bucket}/test.csv\" \n",
    "\n",
    "    train.to_csv(output_train_path)\n",
    "    test.to_csv(output_test_path)\n",
    "\n",
    "    return (train, test)\n",
    "\n",
    "\n",
    "def read_data(\n",
    "    a: InputPath(\"CSV\"),\n",
    "): \n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv(\"gs://mle-dwh-torus/raw/new_test.csv\")\n",
    "\n",
    "# df.columns = [col.lower().strip() for col in df.columns] \n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Read data(a: 'CSV')>"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kfp\n",
    "\n",
    "kfp.components.func_to_container_op(\n",
    "    bq_extract_data,\n",
    "    extra_code=\"from typing import NamedTuple\",\n",
    "    output_component_file='ingest_component.yaml', \n",
    "    base_image='gcr.io/pacific-torus-347809/mle-fp/base:latest')\n",
    "\n",
    "kfp.components.func_to_container_op(\n",
    "    basic_preprocessing,\n",
    "    extra_code=\"from kfp.v2.dsl import Dataset, InputPath, OutputPath\",\n",
    "    output_component_file='basic_preprocessing_component.yaml', \n",
    "    base_image='gcr.io/pacific-torus-347809/mle-fp/base:latest',\n",
    "    packages_to_install=[\"fsspec\", \"gcsfs\"])\n",
    "\n",
    "kfp.components.func_to_container_op(\n",
    "    train_test_split,\n",
    "    extra_code=\"from kfp.v2.dsl import Dataset, InputPath\",\n",
    "    output_component_file='tts_component.yaml', \n",
    "    base_image='gcr.io/pacific-torus-347809/mle-fp/base:latest',\n",
    "    packages_to_install=[\"fsspec\", \"gcsfs\", \"sklearn\"])\n",
    "\n",
    "kfp.components.func_to_container_op(\n",
    "    read_data,\n",
    "    extra_code=\"from kfp.v2.dsl import Dataset, InputPath\",\n",
    "    output_component_file='data_component.yaml', \n",
    "    base_image='gcr.io/pacific-torus-347809/mle-fp/base:latest',\n",
    "    packages_to_install=[\"fsspec\", \"gcsfs\", \"sklearn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_op = kfp.components.load_component_from_file(\"./ingest_component.yaml\")\n",
    "remove_na_op = kfp.components.load_component_from_file(\"./basic_preprocessing_component.yaml\")\n",
    "tts_op = kfp.components.load_component_from_file(\"./tts_component.yaml\")\n",
    "\n",
    "data_op = kfp.components.load_component_from_file(\"./data_component.yaml\")\n",
    "\n",
    "PIPELINE_ROOT = \"{}/pipeline/\".format(\"gs://mle-dwh-torus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "@dsl.pipeline(\n",
    "   name='testing pipeline',\n",
    "   description='NIL',\n",
    "   pipeline_root=PIPELINE_ROOT\n",
    ")\n",
    "def xgboost_test_pipeline(\n",
    "):\n",
    "    ingest = ingest_op(\n",
    "        source_project_id=\"pacific-torus-347809\",\n",
    "        source_table_url=\"dwh_pacific_torus.credit_card_defaults\",\n",
    "        destination_project_id=\"pacific-torus-347809\",\n",
    "        destination_bucket=\"mle-dwh-torus\",\n",
    "        destination_file=\"raw/new_test.csv\",\n",
    "        dataset_location=\"US\",\n",
    "        extract_job_config={},\n",
    "    ) # .apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "\n",
    "    remove_na = remove_na_op(\n",
    "        input_file=ingest.outputs[\"dataset_gcs_uri\"],\n",
    "        output_bucket=\"int\",\n",
    "        output_file=\"ccd2.csv\"\n",
    "    )\n",
    "    \n",
    "    tts = tts_op(\n",
    "        input=remove_na.output,\n",
    "        output_bucket=\"fin\"\n",
    "    )\n",
    "\n",
    "    data = data_op(\n",
    "        a=tts.outputs[\"train_data\"]\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c.san/opt/anaconda3/envs/mle/lib/python3.9/site-packages/kfp/v2/compiler/compiler.py:1263: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineJob created. Resource name: projects/415851101207/locations/us-central1/pipelineJobs/test-232214\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/415851101207/locations/us-central1/pipelineJobs/test-232214')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/test-232214?project=415851101207\n",
      "PipelineJob projects/415851101207/locations/us-central1/pipelineJobs/test-232214 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/415851101207/locations/us-central1/pipelineJobs/test-232214 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/415851101207/locations/us-central1/pipelineJobs/test-232214 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/415851101207/locations/us-central1/pipelineJobs/test-232214 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [train-test-split].; Job (project_id = pacific-torus-347809, job_id = 2427218097803886592) is failed due to the above error.; Failed to handle the job: {project_number = 415851101207, job_id = 2427218097803886592}\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rs/_9wv_fmn5y1d1cxb6xd4q711dh2rk4/T/ipykernel_85572/1965905257.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, service_account, network, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    267\u001b[0m         )\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     def submit(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mle/lib/python3.9/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36m_block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;31m# JOB_STATE_FAILED or JOB_STATE_CANCELLED.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_PIPELINE_ERROR_STATES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job failed with:\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_action_completed_against_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [train-test-split].; Job (project_id = pacific-torus-347809, job_id = 2427218097803886592) is failed due to the above error.; Failed to handle the job: {project_number = 415851101207, job_id = 2427218097803886592}\"\n"
     ]
    }
   ],
   "source": [
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../pacific-torus.json\"\n",
    "from datetime import datetime\n",
    "id = datetime.now().strftime(f\"%d%H%M\")\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=xgboost_test_pipeline,\n",
    "    pipeline_name=\"xgboost-train-pipeline\",\n",
    "    package_path=\"./test.json\",\n",
    "    type_check=True,\n",
    ")\n",
    "\n",
    "job = aip.PipelineJob(\n",
    "    display_name=\"testpipeline\",\n",
    "    template_path=\"./test.json\",\n",
    "    job_id=f'test-{id}',\n",
    "    pipeline_root=PIPELINE_ROOT\n",
    ")\n",
    "\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.components import InputPath, OutputPath, create_component_from_func\n",
    "\n",
    "def xgboost_train(\n",
    "    training_data_path: InputPath('CSV'),  # Also supports LibSVM\n",
    "    model_path: OutputPath('XGBoostModel'),\n",
    "    model_config_path: OutputPath('XGBoostModelConfig'),\n",
    "    starting_model_path: InputPath('XGBoostModel') = None,\n",
    "\n",
    "    label_column: int = 0,\n",
    "    num_iterations: int = 10,\n",
    "    booster_params: dict = None,\n",
    "\n",
    "    # Booster parameters\n",
    "    objective: str = 'reg:squarederror',\n",
    "    booster: str = 'gbtree',\n",
    "    learning_rate: float = 0.3,\n",
    "    min_split_loss: float = 0,\n",
    "    max_depth: int = 6,\n",
    "):\n",
    "    '''Train an XGBoost model.\n",
    "    Args:\n",
    "        training_data_path: Path for the training data in CSV format.\n",
    "        model_path: Output path for the trained model in binary XGBoost format.\n",
    "        model_config_path: Output path for the internal parameter configuration of Booster as a JSON string.\n",
    "        starting_model_path: Path for the existing trained model to start from.\n",
    "        label_column: Column containing the label data.\n",
    "        num_boost_rounds: Number of boosting iterations.\n",
    "        booster_params: Parameters for the booster. See https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "        objective: The learning task and the corresponding learning objective.\n",
    "            See https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters\n",
    "            The most common values are:\n",
    "            \"reg:squarederror\" - Regression with squared loss (default).\n",
    "            \"reg:logistic\" - Logistic regression.\n",
    "            \"binary:logistic\" - Logistic regression for binary classification, output probability.\n",
    "            \"binary:logitraw\" - Logistic regression for binary classification, output score before logistic transformation\n",
    "            \"rank:pairwise\" - Use LambdaMART to perform pairwise ranking where the pairwise loss is minimized\n",
    "            \"rank:ndcg\" - Use LambdaMART to perform list-wise ranking where Normalized Discounted Cumulative Gain (NDCG) is maximized\n",
    "    Annotations:\n",
    "        author: Alexey Volkov <alexey.volkov@ark-kun.com>\n",
    "    '''\n",
    "    import pandas\n",
    "    import xgboost\n",
    "\n",
    "    df = pandas.read_csv(\n",
    "        training_data_path,\n",
    "    )\n",
    "\n",
    "    training_data = xgboost.DMatrix(\n",
    "        data=df.drop(columns=[df.columns[label_column]]),\n",
    "        label=df[df.columns[label_column]],\n",
    "    )\n",
    "\n",
    "    booster_params = booster_params or {}\n",
    "    booster_params.setdefault('objective', objective)\n",
    "    booster_params.setdefault('booster', booster)\n",
    "    booster_params.setdefault('learning_rate', learning_rate)\n",
    "    booster_params.setdefault('min_split_loss', min_split_loss)\n",
    "    booster_params.setdefault('max_depth', max_depth)\n",
    "\n",
    "    starting_model = None\n",
    "    if starting_model_path:\n",
    "        starting_model = xgboost.Booster(model_file=starting_model_path)\n",
    "\n",
    "    model = xgboost.train(\n",
    "        params=booster_params,\n",
    "        dtrain=training_data,\n",
    "        num_boost_round=num_iterations,\n",
    "        xgb_model=starting_model\n",
    "    )\n",
    "\n",
    "    # Saving the model in binary format\n",
    "    model.save_model(model_path)\n",
    "\n",
    "    model_config_str = model.save_config()\n",
    "    with open(model_config_path, 'w') as model_config_file:\n",
    "        model_config_file.write(model_config_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Xgboost train(training_data: 'CSV', starting_model: 'XGBoostModel' = None, label_column: int = '0', num_iterations: int = '10', booster_params: dict = None, objective: str = 'reg:squarederror', booster: str = 'gbtree', learning_rate: float = '0.3', min_split_loss: float = '0', max_depth: int = '6')>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_component_from_func(\n",
    "    xgboost_train,\n",
    "    output_component_file='component.yaml',\n",
    "    base_image='gcr.io/pacific-torus-347809/mle-fp/base:latest',\n",
    "    packages_to_install=[\n",
    "        'xgboost==1.6.1',\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_train_on_csv_op = kfp.components.load_component_from_file(\"./component.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\"pandas\", \"sklearn\", \"fsspec\", \"gcsfs\"],\n",
    "    output_component_file=\"./test_process.yaml\"\n",
    ")\n",
    "def download_from_gcs(\n",
    "    gcs_url: str, \n",
    "    dataset_train: Output[Dataset],\n",
    "    dataset_test: Output[Dataset],\n",
    "    int_upload_url: str = None,\n",
    "):\n",
    "    import logging \n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    logger = logging.getLogger(\"root\")\n",
    "    df = pd.read_csv(gcs_url)\n",
    "\n",
    "    columns = df.columns.to_list()\n",
    "    columns = list(map(lambda col: col.lower().strip(), columns))\n",
    "    df.columns = columns\n",
    "\n",
    "    # drop NA\n",
    "    df.dropna()\n",
    "\n",
    "    train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "    train.to_csv(dataset_train.path)\n",
    "    test.to_csv(dataset_test.path)\n",
    "    logger.info(\"file done\")\n",
    "    print(dataset_test.path, dataset_train.path)\n",
    "\n",
    "\n",
    "ingest_op = kfp.components.load_component_from_file(\"./test_process.yaml\")\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"testing pipe\"\n",
    ")\n",
    "def pipe():\n",
    "    ingest_op(gcs_url=\"gs://mle-dwh-torus/raw/credit_cards.csv\")\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipe,\n",
    "    pipeline_name=\"xgboost-train-pipeline\",\n",
    "    package_path=\"./test.json\",\n",
    "    type_check=True,\n",
    ")\n",
    "\n",
    "# job = aip.PipelineJob(\n",
    "#     display_name=\"testpipeline\",\n",
    "#     template_path=\"./test.json\",\n",
    "#     job_id=\"test-15\",\n",
    "#     pipeline_root=PIPELINE_ROOT,\n",
    "# )\n",
    "\n",
    "# job.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27cbf2f7b5893dafe4e8ecae5261b638a5ae255f0e4bf1f0d62d572ad7f511a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
